---
title: "Final Project"
author: "Luis Señires, Hiroaki Kurachi"
date: today
format: 
  pdf:
    include-in-header: 
       text: |
         \usepackage{fvextra}
         \DefineVerbatimEnvironment{Highlighting}{Verbatim}{breaklines,commandchars=\\\{\}}
include-before-body:
  text: |
    \RecustomVerbatimEnvironment{verbatim}{Verbatim}{
      showspaces = false,
      showtabs = false,
      breaksymbolleft={},
      breaklines
    }
---

# Group member

- Luis Señires(username: ldsenires, section: 1)

- Hiroaki Kurachi(username: hirokurachi, section: 2)

<!-- The primary purpose of this writeup is to inform us of what we are reading before we look at your code. -->

# Back ground

- Green, Social, and Sustainability Bonds
    - Financial securities issued by organizations to raise funding for a portfolio of projects...

    - ...that are expected to generate “green” or “social” (or both!) benefits

    - Borrowers are expected to provide allocation and impact reports

- Environmental Performance Index (EPI)
    - Provided by Yale and Columbia

    - Uses 58 performance indicators across 11 issue categories

    - Ranks 180 countries on climate change performance, environmental health, and ecosystem vitality

# Research question
<!--Describe your research question-->

- What is the relationship between the amount of funding raised through Green and Sustainability bonds and a country’s EPI score?

# Approach
<!--Then discuss the approach you took and the coding involved, including discussing any weaknesses or difficulties encountered -->

- Dataset 1: Bond issuances

    - Green and Sustainability bond issuance volumes (USD millions)

    - Total local currency bond issuance volumes (USD millions)

    - Broken down per issuer (Government and Corporate) and bond label (Green and Sustainability)

    - Limited to ASEAN+3 economies

        - droped China as outlier

    - Taken from the Asian Development Bank’s AsianBondsOnline portal

- Dataset 2: EPI

    - Aggregated into a score

    - Comprehensively covers a wide range of environmental issues, not just a single or limited issues
    
    - Though this analysis is focused on ASEAN+3, dataset contains global information which can be useful especially when comparing against world standards

    - Two-year time horizon which does not directly match Bond data

```{python} 
#| include: False 
# Import required packages.
import os
import altair as alt
import pandas as pd
import numpy as np
#import re
alt.renderers.enable("png")
alt.data_transformers.disable_max_rows() 
```

<!--Data wrangling -->

<!--1 Create df_index -->

```{python} 
#| include: False
# Load 2024 index dataset
path_cwd = (r"C:\Users\hkura\Documents\Uchicago\04 2024 Autumn\Python2\final")
# path_cwd = (r"C:\Users\LUIS\Documents\GitHub\final")

path_indexes = os.path.join(
    path_cwd, r"data\index"
)
path_index_2024 = os.path.join(
    path_indexes, "epi2024results.csv"
)
df_index = pd.read_csv(path_index_2024)

# Extract column including Index values
df_index = df_index[["iso", "country", "EPI.new"]].rename(
    {"EPI.new": 2024}, axis=1
)
```

```{python} 
#| include: False
path_data = os.path.join(
    path_cwd, "data"
)
```

- Clean df_index
```{python} 
#| include: False
# Add each year's result to the dataset from CSVs
for year in range(2016, 2024, 2):
    path_index_add = os.path.join(
        path_indexes, f"{year}-epi.xlsx"
    )
    sheet = {
        2016: 2, 2018: 3, 2020: 4, 2022: 4
    }
    df_add = pd.read_excel(path_index_add, sheet_name=sheet[year])
    if year == 2016:
        df_add = df_add.rename(
            {"Country": "country", "ISO3": "iso", "2016 EPI Score": "EPI.new"},
            axis=1
        )
    elif year == 2018:
        df_add = df_add.rename(
            {"EPI.current": "EPI.new"},
            axis=1
        )
    df_add = df_add[["country", "iso", "EPI.new"]].rename(
        {"EPI.new": year},
        axis=1
    )
    df_index = df_index.merge(
        df_add,
        on=["iso", "country"],
        how="inner"
    )

# Change the columns order
df_index = df_index[["country", "iso", 2016, 2018, 2020, 2022, 2024]]

# Melt the dataset by year
df_index = df_index.melt(
    id_vars=["country", "iso"],
    var_name="Year",
    value_name="EPI"
).sort_values(["iso", "Year"], ascending=True).reset_index(drop=True).rename({"country": "Country Name"}, axis=1)
```

```{python} 
#| include: False
# Create World/ASEAN+3 average row
def calc_annual_average(df, outcome):
    average = df.groupby("Year").agg(
        EPI=("EPI", "mean")
    ).reset_index()
    average[["Country Name", "iso"]] = outcome
    average = average[["Country Name", "iso"]].join(
        average.drop(["Country Name", "iso"], axis=1))
    return average


df_world_average = calc_annual_average(df_index, "Average (World)")
df_index = pd.concat([df_index, df_world_average])

# Filter df_index by Country Name
df_index = df_index[df_index["Country Name"].isin(
    ["Indonesia", "Japan", "Cambodia", "South Korea", "Laos",
        "Malaysia", "Philippines", "Singapore", "Thailand", "Viet Nam", "Average (World)"]
)].reset_index(drop=True)  # Drop China (outlier)

df_asean3_average = calc_annual_average(
    df_index[df_index["Country Name"] != "Average (World)"], "Average (ASEAN+3)")
df_index = pd.concat([df_index, df_asean3_average])
```

```{python} 
#| include: False
# Create new column of "EPI gap from World average"
df_average = pd.concat([df_world_average, df_asean3_average])


def epi_average(year, pop):
    """Return average EPI for corresponding year"""
    average = df_average[(df_average["Year"] == year) & (
        df_average["Country Name"] == pop)]
    average = average.iloc[0]["EPI"]
    return average


df_index["EPI World average"] = [epi_average(
    x, "Average (World)") for x in df_index["Year"]]
df_index["EPI gap from World average"] = df_index["EPI"] - \
    df_index["EPI World average"]

# Create new column of "EPI gap from ASEAN+3 average"
df_index["EPI ASEAN+3 average"] = [epi_average(x, "Average (ASEAN+3)")
                                   for x in df_index["Year"]]
df_index["EPI gap from ASEAN+3 average"] = df_index["EPI"] - \
    df_index["EPI ASEAN+3 average"]

# Save the dataset as csv file
path_index = os.path.join(
    path_data, "index.csv"
)

df_index.to_csv(path_index)
```

<!--2 Create df_bonds_long -->

```{python} 
#| include: False
# Load local currency issuance dataset
path_lcy_issuance = os.path.join(
    path_data, "breakdown of lcy bond market issuance.csv"
)
df_lcy_issuance = pd.read_csv(
    path_lcy_issuance, skiprows=10)

# Drop columns not in USD terms
df_lcy_issuance = df_lcy_issuance.drop(df_lcy_issuance.columns[2:5], axis=1)

# Convert column values to USD millions
df_lcy_issuance.iloc[:, 2:5] = df_lcy_issuance.iloc[:, 2:5] * 1000

# Rename columns
df_lcy_issuance = df_lcy_issuance.rename(columns={
    "Corporate(USD billions)": "corp_lcy",
    "Government(USD billions)": "govt_lcy",
    "Total(USD billions)": "total_lcy",
})
```

```{python} 
#| include: False
# Load bond issuance datasets
path_green_issuance = os.path.join(
    path_data, "green bonds issuance.csv"
)
df_green_issuance = pd.read_csv(path_green_issuance, skiprows=10)

path_sustainability_issuance = os.path.join(
    path_data, "sustainability bonds issuance.csv"
)
df_sustainability_issuance = pd.read_csv(
    path_sustainability_issuance, skiprows=10)

# Merge green and sustainability datasets
df_bonds = df_green_issuance.merge(
    df_sustainability_issuance, on=["Economy", "Date"])

# Rename columns
df_bonds = df_bonds.rename(columns={
    "Government FCY(USD millions)_x": "govt_fcy_green",
    "Corporate FCY(USD millions)_x": "corp_fcy_green",
    "Government LCY(USD millions)_x": "govt_lcy_green",
    "Corporate LCY(USD millions)_x": "corp_lcy_green",
    "Total(USD millions)_x": "total_green",
    "Government FCY(USD millions)_y": "govt_fcy_sustainability",
    "Corporate FCY(USD millions)_y": "corp_fcy_sustainability",
    "Government LCY(USD millions)_y": "govt_lcy_sustainability",
    "Corporate LCY(USD millions)_y": "corp_lcy_sustainability",
    "Total(USD millions)_y": "total_sustainability",
})

# Add columns based on issuer type + bond label
df_bonds["govt_green"] = df_bonds["govt_fcy_green"] + \
    df_bonds["govt_lcy_green"]
df_bonds["corp_green"] = df_bonds["corp_fcy_green"] + \
    df_bonds["corp_lcy_green"]
df_bonds["govt_sustainability"] = df_bonds["govt_fcy_sustainability"] + \
    df_bonds["govt_lcy_sustainability"]
df_bonds["corp_sustainability"] = df_bonds["corp_fcy_sustainability"] + \
    df_bonds["corp_lcy_sustainability"]

# Handle date column
df_bonds = df_bonds.replace("Sep-2024", "2024").infer_objects(copy=False)
df_bonds["Date"] = df_bonds["Date"].astype(int)

# Merge lcy to bonds df
df_bonds = df_bonds.merge(df_lcy_issuance, on=["Economy", "Date"], how="outer")

# Drop China (outlier), Hong Kong (not included in original df_index), and VN*(duplicate)
df_bonds = df_bonds[~df_bonds["Economy"].isin(["CN", "HK", "VN*"])]

# Retain only 2016-2024 data
df_bonds = df_bonds.loc[df_bonds["Date"] > 2015]
```

```{python} 
#| include: False
# Melt df for easier handling
df_bonds_long = df_bonds.melt(
    id_vars=["Economy", "Date"],
    value_vars=['govt_fcy_green', 'corp_fcy_green', 'govt_lcy_green',
                'corp_lcy_green', 'govt_fcy_sustainability',
                'corp_fcy_sustainability', 'govt_lcy_sustainability',
                'corp_lcy_sustainability', 'corp_lcy',
                'govt_lcy'],
    var_name="variable",
    value_name="amount"
)

# Define function to determine issuer type
def get_issuer_type(value):
    if "govt" in value:
        return "Government"
    elif "corp" in value:
        return "Corporate"
    else:
        return np.nan

# Define function to determine currency
def get_currency(value):
    if "lcy" in value:
        return "lcy"
    elif "fcy" in value:
        return "fcy"
    else:
        return np.nan

# Define function to determine bond label
def get_bond_label(value):
    if "green" in value:
        return "Green"
    elif "sustainability" in value:
        return "Sustainability"
    else:
        return np.nan

# Apply functions
df_bonds_long["issuer_type"] = df_bonds_long["variable"].apply(get_issuer_type)
df_bonds_long["currency"] = df_bonds_long["variable"].apply(get_currency)
df_bonds_long["bond_label"] = df_bonds_long["variable"].apply(get_bond_label)

# Rename column
df_bonds_long = df_bonds_long.rename(columns={"Date": "Year"})
```

<!--3 Create closswalk -->

```{python} 
#| include: False
# Identify corresponding country name and iso in df_index
countries_index = df_index[~df_index["Country Name"].isin(["Average (World)", "Average (ASEAN+3)"])][["Country Name", "iso"]].value_counts().reset_index(
).sort_values(
    by="iso", 
    ascending=True
).drop("count", axis=1).reset_index(drop=True)

# Identify corresponding iso("Economy" column) in df_bonds
countries_bonds = df_bonds_long["Economy"].value_counts().reset_index(
).sort_values(
    by="Economy", 
    ascending=True
).drop("count", axis=1).reset_index(drop=True)

# Create crosswalk from country lists
crosswalk = pd.concat([countries_bonds, countries_index], axis=1)
```

<!--3 Merge DFs to make base DF-->

```{python} 
#| include: False
# Merge crosswalk to df_bonds
df_bonds_long = df_bonds_long.merge(
    crosswalk,
    on="Economy",
    how="left"
)
```

```{python} 
#| include: False
# Merge DFs by Country Code and Date/Year
df_base = df_bonds_long.merge(
    df_index,
    on=["iso", "Year", "Country Name"],
    how="left"
)
df_base = df_base.drop(["Economy"], axis=1)

df_base = df_base[["Country Name", "iso"]].join(
    df_base.drop(["Country Name", "iso"], axis=1)
).rename({"Country Name": "Country Name", "iso": "Country Code"}, axis=1)

# Save the dataset as csv file
path_base = os.path.join(
    path_data, "base.csv"
)

df_base.to_csv(path_base)
```


# Findings
<!-- Display static plots, briefly discribe then and our Shiny App -->

## Rising issuance volume

<!--Plots on Bond issuance -->

```{python} 
#| include: False
# Set path to save pictures
path_picture = os.path.join(
    path_cwd, "picture"
)
```

<!--1 Bond issuance over time-->

```{python} 
#| include: False
# Drop bonds with no label
df_base_filtered = df_base.copy()
df_base_filtered = df_base_filtered.dropna(subset="bond_label")

# Plot issuances per year
chart_bonds = alt.Chart(df_base_filtered).mark_bar().encode(
    alt.X("Year:O"),
    alt.Y("amount:Q"),
    alt.Color("Country Name:N")
).properties(
    width=500,
    height=500
)

#chart_bonds.show()

# Save the plot as png
path_picture_bonds = os.path.join(
    path_picture, "chart_bonds.png"
)
chart_bonds.save(path_picture_bonds)
```

<!--2 Borrowing mix-->

```{python} 
#| include: False
# Drop 2024 data
df_base_filtered_total = df_base.loc[df_base["Year"] != 2024]

# Plot borrowing mix
chart_issuer_type_mix_kor = alt.Chart(df_base_filtered_total).transform_filter(
    alt.FieldEqualPredicate(field="Country Code", equal="KOR")
).mark_bar().encode(
    alt.X("amount:Q", stack="normalize"),
    alt.Y("Year:O"),
    alt.Color("bond_label:N"),
    alt.Order("bond_label", sort="descending")
).properties(
    width=500,
    height=500
)

chart_issuer_type_mix_kor.show()

# Save the plot as png
path_picture_mix = os.path.join(
    path_picture, "chart_mix.png"
)
chart_mix.save(path_picture_mix)
```


- Upward trending (in nominal terms)

![Consolidated issuance volume, 2016 - 2024YTD](picture/chart_bonds.png){width=200}

- From Dashboard: By filtering countries on bar chart over time, we can see whethre this trend is common in this area or not.

    - JP, SK contributes to forming the trend with large and increasing volume

    - But other countries such as SG, ID, PH, KH generally increases the issuance based on their own size of volume

- But as the parcentage bar chart shows, notably the rate of these G+S bonds are quite small in the total bonds volume.

![Share of G + S bonds in total bonds, 2016 - 2024](picture/chart_mix.png){width=200}

- Possible reasons:

    - Paris commitments

    - Energy crisis due to geopolitical conflicts

    - Growth of ESG market segment

    - More generally, higher deficits due to the pandemic

## Global downtrend in EPI

<!--Plot EPI-->

<!--1 Nominal EPI-->

```{python} 
#| include: False
# Plot EPI over year, which includes averages summarized in df_index
chart_index = alt.Chart(df_index).mark_line().encode(
    alt.X("Year:O"),
    alt.Y("EPI:Q", scale=alt.Scale(zero=False)),
    alt.Color("Country Name:N", legend=None)
).properties(
    width=500,
    height=500
).transform_filter(
    "(datum.Year==2016)|(datum.Year==2018)|(datum.Year==2020)|(datum.Year==2022)|(datum.Year==2024)"
)

chart_index_text = alt.Chart(df_index).transform_filter(
    "datum.Year == 2024"
).mark_text(
    align="left", baseline="middle", dx=7
).encode(
    text="Country Name:N",
    x="Year:O",
    y="EPI:Q",
    color="Country Name:N"
)

chart_index = chart_index + chart_index_text

#chart_index.show()

# Save the plot as png
path_picture_index = os.path.join(
    path_picture, "chart_index.png"
)
chart_index.save(path_picture_index)
```

<!--2 Gap from world average-->

```{python} 
#| include: False
# Plot each country's gap from World average over year
chart_index_standardized = alt.Chart(df_base).mark_line().encode(
    alt.X("Year:O"),
    alt.Y("EPI gap from World average:Q"),
    alt.Color("Country Name:N", legend=None)
).properties(
    width=500,
    height=500
).transform_filter(
    "(datum.Year==2016)|(datum.Year==2018)|(datum.Year==2020)|(datum.Year==2022)|(datum.Year==2024)"
)

chart_index_standardized_text = alt.Chart(df_base).transform_filter(
    "datum.Year == 2024"
).mark_text(
    align="left", baseline="middle", dx=7
).encode(
    text="Country Name:N",
    x="Year:O",
    y="EPI gap from World average:Q",
    color="Country Name:N"
)

chart_index_standardized = chart_index_standardized + chart_index_standardized_text

#chart_index_standardized.show()

# Save the plot as png
path_picture_index_standardized = os.path.join(
    path_picture, "chart_index_standardized.png"
)
chart_index_standardized.save(path_picture_index_standardized)
```

- Regional (and global) drop in EPI scores

![EPI scores, 2016 - 2024](picture/chart_index.png){width=200}

- From Dashboard: We can also convert the nominal values into the gap from world average. As we see the relative performance of each countries, the scores of ASEAN+3 countries other than JP, SK and SG are lower than the average. And the whole ASEAN+3 trend is still on downtrend.

- Possible reasons:

    - Higher standards for performance

    - More developments focused on economic growth rather than environmental targets

## Weak to negative relation 

<!-- plot for association btw/n Bonds and EPI -->

```{python} 
#| include: False
# Plot idea
# Drop bonds with no label
df_base_filtered = df_base.dropna(subset="bond_label")

# Normalize amount and EPI gap from world average
df_base_filtered["amount_norm"] = (df_base_filtered["amount"] - df_base_filtered["amount"].min()) / (df_base_filtered["amount"].max() - df_base_filtered["amount"].min())

df_base_filtered["EPI_gap_norm"] = (df_base_filtered["EPI gap from World average"] - df_base_filtered["EPI gap from World average"].min()) / (df_base_filtered["EPI gap from World average"].max() - df_base_filtered["EPI gap from World average"].min())

# Plot issuances per year
chart_bonds = alt.Chart(df_base_filtered).mark_point().transform_filter(
    alt.FieldEqualPredicate(field="Country Code", equal="KOR")
).encode(
    alt.X("Year:O"),
    alt.Y("sum(amount_norm):Q"),
    alt.Color("Country Name:N")
).properties(
    width=500,
    height=500
)

bonds_trend_line = alt.Chart(df_base_filtered).mark_line(color="red").transform_filter(
    alt.FieldEqualPredicate(field="Country Code", equal="KOR")
).transform_aggregate(
    sum_amount="sum(amount_norm)",
    groupby=["Year"]
).transform_regression(
    "Year", "sum_amount", method="linear"
).encode(
    alt.X("Year:O"),
    alt.Y("sum_amount:Q")
)

combined_bonds = chart_bonds + bonds_trend_line

chart_index_standardized = alt.Chart(df_base_filtered).mark_point().transform_filter(
    alt.FieldEqualPredicate(field="Country Code", equal="KOR")
).encode(
    alt.X("Year:O"),
    alt.Y("EPI_gap_norm:Q"),
    alt.Color("Country Name:N", legend=None)
).properties(
    width=500,
    height=500
).transform_filter(
    "(datum.Year==2016)|(datum.Year==2018)|(datum.Year==2020)|(datum.Year==2022)|(datum.Year==2024)"
)

index_trend_line = alt.Chart(df_base_filtered).mark_line(color="blue").transform_filter(
    alt.FieldEqualPredicate(field="Country Code", equal="KOR")
).transform_regression(
    "Year", "EPI_gap_norm", method="linear"
).encode(
    alt.X("Year:O"),
    alt.Y("EPI_gap_norm:Q")
)

combined_index = chart_index_standardized + index_trend_line

combined = combined_bonds + combined_index
combined.show()

# Save the plot as png
path_picture_index = os.path.join(
    path_picture, "chart_combined_with_trend.png"
)
combined.save(path_picture_index)
```

- Plot example: South Korea

![Linear Regression on time series data (Consolidated issuance volume, EPI score, 2016 - 2024](picture/chart_combined_with_trend.png){width=200}

- From Dashboard: we can see other countries' result

- Linear regression on time series data to draw trend lines

- Normalized data for more meaningful comparison

    - Bonds are expressed in USD millions

    - EPI scores are 0 to 100

# Summary and areas for further research
<!-- Finish with a discussion of directions for future work -->

- Summary
    - Lower scores observed despite higher issuance volumes

    - Possible that EPI scores would have decreased even more if not for these investments

    - Could be a signal of “greenwashing”

- Areas for further research
    - Use of project-level data or more specific categorization of use of proceeds

    - Other potential determinants of EPI scores (e.g. GDP, specific investments into renewable energy, etc.)

    - Other peer comparisons aside from region

```{python} 
#| include: False
# # Bin the bonds issuance for each EPI term
# def year_bin(year):
#     if year == 2016:
#         bin = "2016"
#     elif (year == 2017) | (year == 2018):
#         bin = "2018"
#     elif (year == 2019) | (year == 2020):
#         bin = "2020"
#     elif (year == 2021) | (year == 2022):
#         bin = "2022"
#     elif (year == 2023) | (year == 2024):
#         bin = "2024"
#     return bin
# year_bin = [year_bin(y) for y in df_base["Year"]]
# df_base["Year_bin"] = year_bin

# # Calculate average growth rate in bonds issuance over time
# bonds_growth = df_base.groupby("Year_bin").agg(
#     average=("amount", "mean")
# ).reset_index()

# bonds_growth["Bonds issuance"] = bonds_growth["average"] / bonds_growth.iloc[0]["average"]

# bonds_growth.drop("average", axis=1)

# # Calculate average growth rate in EPI (standardized) over time
# index_growth = df_base.groupby("Year_bin").agg(
#     average=("EPI gap from World average", "mean")
# ).reset_index()

# index_growth["EPI"] = index_growth["average"] / index_growth.iloc[0]["average"]

# index_growth.drop("average", axis=1)

# # Merge DFs and melt it
# df_growth = bonds_growth.merge(
#     index_growth,
#     on="Year_bin",
#     how="inner"
# )

# df_growth = df_growth.melt(
#     id_vars=["Year_bin"],
#     value_vars=["Bonds issuance", "EPI"],
#     var_name="variable",
#     value_name="growth_rate"
# )

# # Create plot of both growth
# chart_association = alt.Chart(df_growth).mark_line().encode(
#     alt.X("Year_bin:O", title="Year"),
#     alt.Y("growth_rate:Q", title="Growth rate from 2016 over time"),
#     alt.Color("variable:N")
# ).properties(
#     width=600,
#     height=200
# )

# chart_association.show()

# # Save the plot as png
# path_association = os.path.join(
#     path_picture, "chart_association.png"
# )
# chart_association.save(path_association)
```
```{python} 
#| include: False
# # Bin the bonds issuance for each EPI term
# def year_bin(year):
#     if year == 2016:
#         bin = "2016"
#     elif (year == 2017) | (year == 2018):
#         bin = "2017-2018"
#     elif (year == 2019) | (year == 2020):
#         bin = "2019-2020"
#     elif (year == 2021) | (year == 2022):
#         bin = "2021-2022"
#     elif (year == 2023) | (year == 2024):
#         bin = "2023-2024"
#     return bin
# year_bin = [year_bin(y) for y in df_base["Year"]]
# df_base["Year_bin"] = year_bin

# # Plot issuances per bins
# chart_bonds_bin = alt.Chart(df_base).mark_bar().encode(
#     alt.X("Year_bin:N"),
#     alt.Y("total_combined:Q"),
#     alt.Color("Country Name:N")
# ).transform_calculate(
#     total_combined="datum.total_green + datum.total_sustainability"
# ).properties(
#     width=500,
#     height=500
# )

# #.transform_filter("datum.Year_bin == '~~~'")

# chart_bonds_bin.show()

# # Thailand & Malaysia successfully raise EPI, as well as Japan, South Korea, and Singapore. Philippines and Indonesia not.
# # Singapore: the bond issuance amount is consistently not high, but much more highly elastic than Japan and Korea somehow.
```


```{python} 
#| include: False
# # Plot idea: gap from 2016 in bond issuance over time
# df_base["total_combined"] = df_base["total_green"] + \
#     df_base["total_sustainability"]

# gap_combined = df_base.groupby("Country Name")["total_combined"].first().reset_index().rename(columns={"total_combined": "gap_combined"})

# df_base = df_base.merge(
#     gap_combined,
#     on = "Country Name",
#     how = "inner"
# )

# df_base["gap_combined"] = df_base["total_combined"] - df_base["gap_combined"]

# # Plot gap from 2016 in bond issuance over time
# chart_bonds_gap = alt.Chart(df_base).mark_line().encode(
#     alt.X("Year:O"),
#     alt.Y("gap_combined:Q"),
#     alt.Color("Country Name:N")
# ).properties(
#     width=500,
#     height=500
# )

# chart_bonds_gap.show()
```

```{python} 
#| include: False
# # Plot idea: average growth rate in bond issuance over time
# df_base["total_combined"] = df_base["total_green"] + \
#     df_base["total_sustainability"]

# df_base["base_combined"] = df_base.groupby("Country Name")["total_combined"].shift(1).fillna(0)

# df_base["growth_combined"] = df_base["total_combined"] / df_base["base_combined"]
# df_base = df_base[~df_base["growth_combined"].isna()]

# # Plot average growth rate in bond issuance over time
# chart_bonds_growth = alt.Chart(df_base).transform_aggregate(
#     groupby=["Country Name"],
#     growth_combined_average = "average(growth_combined)"
# ).mark_bar().encode(
#     alt.X("Country Name:N", sort="-y"),
#     alt.Y("growth_combined_average:Q"),
#     alt.Color("Country Name:N")
# ).properties(
#     width=500,
#     height=500
# )

# chart_bonds_growth.show()

# ## Except some outliers(Indonesia for extremely high growth; Japan and Korea has moderate growth, but the total amount is quite high), it might explain the tiers in EPI (high, medium, low)
```
```{python} 
#| include: False
# # Plot issuances per year
# df_base_nonJPSK = df_base[(df_base["Country Name"] != "Japan")&(df_base["Country Name"] != "South Korea")]

# chart_bonds_nonJPSK = alt.Chart(df_base_nonJPSK).mark_bar().encode(
#     alt.X("Year:O"),
#     alt.Y("total_green:Q"),
#     alt.Color("Country Name:N")
# ).properties(
#     width=500,
#     height=500
# )

# chart_bonds_nonJPSK.show()
```

```{python} 
#| include: False
# # Plot idea
# df_bond_label = df_base_long.groupby(["Country Name", "Year"]).size().reset_index().drop(0, axis=1)

# bond_label_rate = []
# for c, y in zip(df_bond_label["Country Name"], df_bond_label["Year"]):
#     df_subset = df_base_long[(df_base_long["Country Name"] == c) & (df_base_long["Year"] == y)]
#     if df_subset["amount"].sum() != 0:
#         green_amount = df_subset[df_subset["bond_label"] == "green"]["amount"].sum()
#         total_amount = df_subset["amount"].sum()
#         rate = green_amount/total_amount
#     else:
#         rate = np.nan
#     bond_label_rate.append(rate)

# df_bond_label["bond_label_rate"] = bond_label_rate
# df_bond_label

# chart_bond_label_mix = alt.Chart(df_bond_label).transform_aggregate(
#     groupby=["Country Name"],
#     variance="variance(bond_label_rate)"
# ).mark_bar().encode(
#     alt.X("Country Name:N"),
#     alt.Y("variance:Q"),
#     alt.Color("Country Name:N")
# ).properties(
#     width=500,
#     height=500
# )

# chart_bond_label_mix
```



