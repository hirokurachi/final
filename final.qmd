---
title: "Final Project"
author: "Luis SeÃ±ires(username: ldsenires, section: 1), Hiroaki Kurachi(username: hirokurachi, section: 2)"
date: today
format: 
  pdf:
    include-in-header: 
       text: |
         \usepackage{fvextra}
         \DefineVerbatimEnvironment{Highlighting}{Verbatim}{breaklines,commandchars=\\\{\}}
include-before-body:
  text: |
    \RecustomVerbatimEnvironment{verbatim}{Verbatim}{
      showspaces = false,
      showtabs = false,
      breaksymbolleft={},
      breaklines
    }
---

```{python} 
# Import required packages.
import zipfile
import os
import pandas as pd
import altair as alt
import pandas as pd
from datetime import date, time
import numpy as np
import re
import requests
import json
alt.renderers.enable("png")
alt.data_transformers.disable_max_rows() 
```

# Data wrangling

- Create df_index

    - Extract column including Index values from 2024 result CSV, changing the column name (-> base df)

    - Iterate below process for each year's result CSV till 2022

        - Extract column including Index values

        - Sort the rows (countries) aligned with 2024 data

        - add the column to the base df, changing the column name
```{python}
# Load 2024 index dataset
# path_cwd = (r"C:\Users\hkura\Documents\Uchicago\04 2024 Autumn\Python2\final")
path_cwd = (r"C:\Users\LUIS\Documents\GitHub\final")

path_index = os.path.join(
    path_cwd, r"data\index"
)
path_index_2024 = os.path.join(
    path_index, "epi2024results.csv"
)
df_index = pd.read_csv(path_index_2024)

# Extract column including Index values
df_index = df_index[["iso", "country", "EPI.new"]].rename(
    {"EPI.new": 2024}, axis=1
)
```

```{python}
# Add each year's result to the dataset from CSVs
for year in range(2016, 2024, 2):
    path_index_add = os.path.join(
        path_index, f"{year}-epi.xlsx"
    )
    sheet = {
        2016: 2, 2018: 3, 2020: 4, 2022: 4
    }
    df_add = pd.read_excel(path_index_add, sheet_name=sheet[year])
    if year == 2016:
        df_add = df_add.rename(
            {"Country": "country", "ISO3": "iso", "2016 EPI Score": "EPI.new"}, 
            axis=1
        )
    elif year == 2018:
        df_add = df_add.rename(
            {"EPI.current": "EPI.new"}, 
            axis=1
        )
    df_add = df_add[["country", "iso", "EPI.new"]].rename(
        {"EPI.new": year}, 
        axis=1
    )
    df_index = df_index.merge(
        df_add,
        on=["iso", "country"],
        how="inner"
    )

# Change the columns order
df_index = df_index[["country", "iso", 2016, 2018, 2020, 2022, 2024]]

# Melt the dataset by year
df_index = df_index.melt(
    id_vars=["country", "iso"],
    var_name="Year",
    value_name="EPI"
).sort_values(["iso", "Year"], ascending=True).reset_index(drop=True)
```

- Clean df_issuance

    - Drop observations in 2023 and Sep-2024

    - Replace 0.0 by NA?

```{python}
# Load bond issuance datasets
path_data = os.path.join(
    path_cwd, "data"
)

path_green_issuance = os.path.join(
    path_data, "green bonds issuance.csv"
)
df_green_issuance = pd.read_csv(path_green_issuance, skiprows=10)

path_sustainability_issuance = os.path.join(
    path_data, "sustainability bonds issuance.csv"
)
df_sustainability_issuance = pd.read_csv(
    path_sustainability_issuance, skiprows=10)
```

```{python}
# Merge bond datasets
df_bonds = df_green_issuance.merge(
    df_sustainability_issuance, on=["Economy", "Date"])

df_bonds = df_bonds.rename(columns={
    "Government FCY(USD millions)_x": "govt_fcy_green",
    "Corporate FCY(USD millions)_x": "corp_fcy_green",
    "Government LCY(USD millions)_x": "govt_lcy_green",
    "Corporate LCY(USD millions)_x": "corp_lcy_green",
    "Total(USD millions)_x": "total_green",
    "Government FCY(USD millions)_y": "govt_fcy_sustainability",
    "Corporate FCY(USD millions)_y": "corp_fcy_sustainability",
    "Government LCY(USD millions)_y": "govt_lcy_sustainability",
    "Corporate LCY(USD millions)_y": "corp_lcy_sustainability",
    "Total(USD millions)_y": "total_sustainability",
})
```

```{python}
# Identify corresponding country name and iso in df_index
countries_index = df_index[["country", "iso"]].value_counts().reset_index(
).sort_values(by="iso", ascending=True)

countries_index = countries_index[countries_index["country"].isin(
    ["Indonesia", "Japan", "Cambodia", "South Korea", "Laos",
        "Malaysia", "Philippines", "Singapore", "Thailand", "Viet Nam"]
)].reset_index(drop=True).drop(
    "count", 
    axis=1
)  # Drop China (outlier)

# Identify corresponding iso("Economy" column) in df_issuance
countries_issuance = df_bonds["Economy"].value_counts().reset_index().sort_values(
    by="Economy", 
    ascending=True
)

countries_issuance = countries_issuance[~countries_issuance["Economy"].isin(
    ["CN", "HK"]
)].reset_index(drop=True).drop(
    "count", 
    axis=1
)  # Drop China (outlier) and Hong Kong (not included in original df_index)

# Create crosswalk from country lists
crosswalk = pd.concat([countries_issuance, countries_index], axis=1)
```

```{python}
# Filter df_index by country
df_index = df_index[df_index["country"].isin(
    ["Indonesia", "Japan", "Cambodia", "South Korea", "Laos",
        "Malaysia", "Philippines", "Singapore", "Thailand", "Viet Nam"]
)].reset_index(drop=True)
```

```{python}
# Merge crosswalk to df_issuance
df_bonds = df_bonds.merge(
    crosswalk,
    on="Economy",
    how="inner"
)

# Clean df_issuance, align with df_index
df_bonds = df_bonds.rename(columns={"Date": "Year"})
df_bonds = df_bonds.apply(lambda x: np.where(x == 0.0, np.nan, x))
df_bonds = df_bonds.replace("Sep-2024", "2024").infer_objects(copy=False)
df_bonds["Year"] = df_bonds["Year"].astype(int)
```

```{python}
# Merge DFs by Country Code and Date/Year
df_base = df_bonds.merge(
    df_index,
    on=["iso", "Year", "country"],
    how="left"
)
df_base = df_base.drop(["Economy"], axis=1)

df_base = df_base[["country", "iso"]].join(
    df_base.drop(["country", "iso"], axis=1)
).rename({"country": "Country Name", "iso": "Country Code"}, axis=1)

# Save the dataset as csv file
path_base = os.path.join(
    path_data, "base.csv"
)

df_base.to_csv(path_base)
```

```{python}
# Set path to save pictures
path_picture = os.path.join(
    path_cwd, "picture"
)
```

```{python}
# Plot EPI over year
chart_index = alt.Chart(df_index).mark_line().encode(
    alt.X("Year:O"),
    alt.Y("EPI:Q", scale=alt.Scale(zero=False)),
    alt.Color("country:N", legend=None)
).properties(
    width=500,
    height=500
)

chart_index_text = alt.Chart(df_index).transform_filter(
    "datum.Year == 2024"
).mark_text(
    align="left", baseline="middle", dx=7
).encode(
    text="country:N",
    x="Year:O",
    y="EPI:Q",
    color="country:N"
)

chart_index = chart_index + chart_index_text

chart_index.show()

# Save the plot as png
os.makedirs(path_picture, exist_ok=True)
path_picture_index = os.path.join(
    path_picture, "chart_index.png"
)
chart_index.save(path_picture_index)
```


```{python}
# Plot issuances per year
chart_bonds = alt.Chart(df_bonds).mark_bar().encode(
    alt.X("Year:O"),
    alt.Y("total_green:Q"),
    alt.Color("Economy:N")
).properties(
    width=500,
    height=500
)

chart_bonds
```