---
title: "Final Project"
author: "Luis Se√±ires(id: ldsenires, section:1), Hiroaki Kurachi(id: hiroakik, section:2)"
date: today
format: 
  pdf:
    include-in-header: 
       text: |
         \usepackage{fvextra}
         \DefineVerbatimEnvironment{Highlighting}{Verbatim}{breaklines,commandchars=\\\{\}}
include-before-body:
  text: |
    \RecustomVerbatimEnvironment{verbatim}{Verbatim}{
      showspaces = false,
      showtabs = false,
      breaksymbolleft={},
      breaklines
    }
---

```{python} 
# Import required packages.
import zipfile
import os
import pandas as pd
import altair as alt
import pandas as pd
from datetime import date, time
import numpy as np
import re
import requests
import json
alt.renderers.enable("png")
alt.data_transformers.disable_max_rows() 
```


```{python}
# Load original datasets
path_data = (r"C:\Users\hkura\Documents\Uchicago\04 2024 Autumn\Python2\final\data")

path_issuance = os.path.join(
    path_data,
    "green bonds issuance.csv"
)
df_issuance = pd.read_csv(path_issuance, skiprows=10)

path_emission = os.path.join(
    path_data,
    "35d2dc7f-8c17-4948-98fd-bf459e6a75cc_Data.csv"
)
df_emission = pd.read_csv(path_emission, on_bad_lines="skip")
```

# Data wrangling
Goal: Merge df_emission into df_issuance, by melting df_emission by year

- Clean df_emission

    - remove redundant rows (metadata, etc. contained)

    - Replace erroneous value by NA

    - Drop 2023 columns, as all data is NA

    - Filter series name: focus on total emissions and total per capita excluding LULUCF (drop "% change from 1990" and "including LULUCF")

    - Melt by year

    - Pivot "Series Name" to make them as distinct columns

- Create crosswalk between df_emission and df_issuance

    - Replace "Economy" column in df_issuance, align with "Country Code" in df_emission

- Clean df_issuance

    - Drop observations in 2023 and Sep-2024

    - Replace 0.0 by NA?

- Merge DFs by Country Code


```{python}
# Clean df_emission
df_emission = df_emission.iloc[0:56]
df_emission = df_emission.apply(lambda x: np.where(x == "..", np.nan, x))

# Drop 2023 column, as all data is NA
df_emission = df_emission.drop("2023 [YR2023]", axis=1)

# Filter by "Series Name" column
df_emission = df_emission[(df_emission["Series Code"] == "EN.GHG.ALL.MT.CE.AR5") | (
    df_emission["Series Code"] == "EN.GHG.ALL.PC.CE.AR5")]

# Melt by year
df_emission = df_emission.melt(
    id_vars=["Country Name", "Country Code", "Series Name", "Series Code"],
    var_name="Year",
    value_name="Total Emission"
).sort_values(["Country Code", "Year", "Series Code"], ascending=True).reset_index(drop=True).drop("Series Code", axis=1)

# Clean year name
df_emission["Year"] = df_emission["Year"].str[:4].astype(int)

# Pivot by "Series Name" to make them as distinct columns
df_emission = df_emission.pivot(
    index=["Country Name", "Country Code", "Year"],
    columns="Series Name",
    values="Total Emission"
).reset_index().rename(
    columns={"Total greenhouse gas emissions excluding LULUCF (Mt CO2e)": "Total Emissions",
             "Total greenhouse gas emissions excluding LULUCF per capita (t CO2e/capita)": "Total Emissions per capita"}
)
```


```{python}
# Drop Brunei and Myanmar from df_emission
df_emission = df_emission[(df_emission["Country Code"] != "BRN") & (
    df_emission["Country Code"] != "MMR")]

# Identify corresponding country codes between DFs
countries_emission = df_emission[["Country Name", "Country Code"]].value_counts().reset_index(
).sort_values(by="Country Code", ascending=True).reset_index(drop=True).drop("count", axis=1)
countries_issuance = df_issuance["Economy"].value_counts().reset_index().sort_values(
    by="Economy", ascending=True).reset_index(drop=True).drop("count", axis=1)

# Join dataframes for country code
crosswalk = pd.concat([countries_issuance, countries_emission], axis=1).drop(
    "Country Name", axis=1)

# Merge crosswalk to df_issuance
df_issuance = df_issuance.merge(
    crosswalk,
    on="Economy",
    how="inner"
)
```


```{python}
# Clean df_issuance, align with df_emission
df_issuance = df_issuance[(df_issuance["Date"] != "2023") & (
    df_issuance["Date"] != "Sep-2024")].reset_index(drop=True).rename(columns={"Date": "Year"})
df_issuance = df_issuance.apply(lambda x: np.where(x == 0.0, np.nan, x))
df_issuance["Year"] = df_issuance["Year"].astype(int)
```


```{python}
# Merge DFs by Country Code and Date/Year
df_base = df_issuance.merge(
    df_emission,
    on=["Country Code", "Year"],
    how="inner"
)
df_base = df_base.drop(["Economy"], axis=1)

df_base = df_base[["Country Name", "Country Code"]].join(
    df_base.drop(["Country Name", "Country Code"], axis=1))

path_base = os.path.join(
    path_data,
    "base.csv"
)

df_base.to_csv(path_base)
```